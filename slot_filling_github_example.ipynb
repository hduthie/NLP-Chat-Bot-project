{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train...\n",
      "Downloading valid...\n",
      "Downloading test...\n",
      "Downloading vocab.intent...\n",
      "Downloading vocab.slot...\n"
     ]
    }
   ],
   "source": [
    "SNIPS_DATA_BASE_URL = (\n",
    "    \"https://github.com/ogrisel/slot_filling_and_intent_detection_of_SLU/blob/\"\n",
    "    \"master/data/snips/\"\n",
    ")\n",
    "for filename in [\"train\", \"valid\", \"test\", \"vocab.intent\", \"vocab.slot\"]:\n",
    "    path = Path(filename)\n",
    "    if not path.exists():\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urlretrieve(SNIPS_DATA_BASE_URL + filename + \"?raw=true\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line of training set: Add:O Don:B-entity_name and:I-entity_name Sherri:I-entity_name to:O my:B-playlist_owner Meditate:B-playlist to:I-playlist Sounds:I-playlist of:I-playlist Nature:I-playlist playlist:O <=> AddToPlaylist.\n"
     ]
    }
   ],
   "source": [
    "lines_train = Path('train').read_text('utf-8').strip().splitlines()\n",
    "print(f'First line of training set: {lines_train[0]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent_label': 'AddToPlaylist',\n",
       " 'words': 'Add Don and Sherri to my Meditate to Sounds of Nature playlist',\n",
       " 'words_label': 'O B-entity_name I-entity_name I-entity_name O B-playlist_owner B-playlist I-playlist I-playlist I-playlist I-playlist O',\n",
       " 'length': 12}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_line(line):\n",
    "    utterance_data, intent_label = line.split(\" <=> \")\n",
    "    items = utterance_data.split()\n",
    "    words = [item.rsplit(':', 1)[0] for item in items]\n",
    "    word_labels = [item.rsplit(':', 1)[1] for item in items]\n",
    "    return {\n",
    "        'intent_label': intent_label,\n",
    "        'words': \" \".join(words),\n",
    "        'words_label': \" \".join(word_labels),\n",
    "        'length': len(words)\n",
    "    }\n",
    "\n",
    "parse_line(lines_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddToPlaylist\n",
      "BookRestaurant\n",
      "GetWeather\n",
      "PlayMusic\n",
      "RateBook\n",
      "SearchCreativeWork\n",
      "SearchScreeningEvent\n",
      "\n",
      "B-album\n",
      "B-artist\n",
      "B-best_rating\n",
      "B-city\n",
      "B-condition_description\n",
      "B-condition_temperature\n",
      "B-country\n",
      "B-cuisine\n",
      "B-current_location\n",
      "B-entity_name\n",
      "B-facility\n",
      "B-genre\n",
      "B-geographic_poi\n",
      "B-location_name\n",
      "B-movie_name\n",
      "B-movie_type\n",
      "B-music_item\n",
      "B-object_location_type\n",
      "B-object_name\n",
      "B-object_part_of_series_type\n",
      "B-object_select\n",
      "B-object_type\n",
      "B-party_size_description\n",
      "B-party_size_number\n",
      "B-playlist\n",
      "B-playlist_owner\n",
      "B-poi\n",
      "B-rating_unit\n",
      "B-rating_value\n",
      "B-restaurant_name\n",
      "B-restaurant_type\n",
      "B-served_dish\n",
      "B-service\n",
      "B-sort\n",
      "B-spatial_relation\n",
      "B-state\n",
      "B-timeRange\n",
      "B-track\n",
      "B-year\n",
      "I-album\n",
      "I-artist\n",
      "I-city\n",
      "I-country\n",
      "I-cuisine\n",
      "I-current_location\n",
      "I-entity_name\n",
      "I-facility\n",
      "I-genre\n",
      "I-geographic_poi\n",
      "I-location_name\n",
      "I-movie_name\n",
      "I-movie_type\n",
      "I-music_item\n",
      "I-object_location_type\n",
      "I-object_name\n",
      "I-object_part_of_series_type\n",
      "I-object_select\n",
      "I-object_type\n",
      "I-party_size_description\n",
      "I-playlist\n",
      "I-playlist_owner\n",
      "I-poi\n",
      "I-restaurant_name\n",
      "I-restaurant_type\n",
      "I-served_dish\n",
      "I-service\n",
      "I-sort\n",
      "I-spatial_relation\n",
      "I-state\n",
      "I-timeRange\n",
      "I-track\n",
      "O\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Path('vocab.intent').read_text('utf-8'))\n",
    "print(Path('vocab.slot').read_text('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent_label</th>\n",
       "      <th>words</th>\n",
       "      <th>words_label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>Add Don and Sherri to my Meditate to Sounds of...</td>\n",
       "      <td>O B-entity_name I-entity_name I-entity_name O ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>put United Abominations onto my rare groove pl...</td>\n",
       "      <td>O B-entity_name I-entity_name O B-playlist_own...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>add the tune by misato watanabe to the Trapeo ...</td>\n",
       "      <td>O O B-music_item O B-artist I-artist O O B-pla...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>add this artist to my this is miguel bosé play...</td>\n",
       "      <td>O O B-music_item O B-playlist_owner B-playlist...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>add heresy and the hotel choir to the evening ...</td>\n",
       "      <td>O B-entity_name I-entity_name I-entity_name I-...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    intent_label                                              words  \\\n",
       "0  AddToPlaylist  Add Don and Sherri to my Meditate to Sounds of...   \n",
       "1  AddToPlaylist  put United Abominations onto my rare groove pl...   \n",
       "2  AddToPlaylist  add the tune by misato watanabe to the Trapeo ...   \n",
       "3  AddToPlaylist  add this artist to my this is miguel bosé play...   \n",
       "4  AddToPlaylist  add heresy and the hotel choir to the evening ...   \n",
       "\n",
       "                                         words_label  length  \n",
       "0  O B-entity_name I-entity_name I-entity_name O ...      12  \n",
       "1  O B-entity_name I-entity_name O B-playlist_own...       8  \n",
       "2  O O B-music_item O B-artist I-artist O O B-pla...      10  \n",
       "3  O O B-music_item O B-playlist_owner B-playlist...      10  \n",
       "4  O B-entity_name I-entity_name I-entity_name I-...      11  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed = [parse_line(line) for line in lines_train]\n",
    "df_train = pd.DataFrame([p for p in parsed if p is not None])\n",
    "# Print some lines of the training set\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intent_label\n",
       "GetWeather              1900\n",
       "PlayMusic               1900\n",
       "BookRestaurant          1873\n",
       "SearchScreeningEvent    1859\n",
       "RateBook                1856\n",
       "SearchCreativeWork      1854\n",
       "AddToPlaylist           1842\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of lines by intent label\n",
    "df_train.intent_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get validation and test set\n",
    "lines_validation = Path('valid').read_text('utf-8').strip().splitlines()\n",
    "lines_test = Path('test').read_text('utf-8').strip().splitlines()\n",
    "\n",
    "df_validation = pd.DataFrame([parse_line(line) for line in lines_validation])\n",
    "df_test = pd.DataFrame([parse_line(line) for line in lines_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add Don and Sherri to my Meditate to Sounds of Nature playlist\n"
     ]
    }
   ],
   "source": [
    "first_sentence = df_train.iloc[0]['words']\n",
    "print(first_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ad',\n",
       " '##d',\n",
       " 'Don',\n",
       " 'and',\n",
       " 'She',\n",
       " '##rri',\n",
       " 'to',\n",
       " 'my',\n",
       " 'Me',\n",
       " '##dit',\n",
       " '##ate',\n",
       " 'to',\n",
       " 'Sounds',\n",
       " 'of',\n",
       " 'Nature',\n",
       " 'play',\n",
       " '##list']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(first_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 24930,\n",
       " 1181,\n",
       " 1790,\n",
       " 1105,\n",
       " 1153,\n",
       " 14791,\n",
       " 1106,\n",
       " 1139,\n",
       " 2508,\n",
       " 17903,\n",
       " 2193,\n",
       " 1106,\n",
       " 10560,\n",
       " 1104,\n",
       " 7009,\n",
       " 1505,\n",
       " 7276,\n",
       " 102]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode sentence to id\n",
    "tokenizer.encode(first_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Add Don and Sherri to my Meditate to Sounds of Nature playlist [SEP]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the inverse operation\n",
    "tokenizer.decode(tokenizer.encode(first_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ä', 250),\n",
       " ('å', 251),\n",
       " ('æ', 252),\n",
       " ('ç', 253),\n",
       " ('è', 254),\n",
       " ('é', 255),\n",
       " ('ê', 256),\n",
       " ('ë', 257),\n",
       " ('ì', 258),\n",
       " ('í', 259)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the items in BERT\n",
    "bert_vocab_items = list(tokenizer.vocab.items())\n",
    "# Print some examples of items\n",
    "bert_vocab_items[250:260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dataset(tokenizer, text_sequences, max_length):\n",
    "    token_ids = np.zeros(shape=(len(text_sequences), max_length),\n",
    "                         dtype=np.int32)\n",
    "    for i, text_sequence in enumerate(text_sequences):\n",
    "        encoded = tokenizer.encode(text_sequence)\n",
    "        token_ids[i, 0:len(encoded)] = encoded\n",
    "    attention_masks = (token_ids != 0).astype(np.int32)\n",
    "    \n",
    "    return {'input_ids': token_ids, 'attention_masks': attention_masks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = encode_dataset(tokenizer, df_train['words'], 45)\n",
    "encoded_validation = encode_dataset(tokenizer, df_validation['words'], 45)\n",
    "encoded_test = encode_dataset(tokenizer, df_test['words'], 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_names = Path('vocab.intent').read_text('utf-8').split()\n",
    "intent_map = dict((label, idx) for idx, label in enumerate(intent_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_train = df_train['intent_label'].map(intent_map).values\n",
    "intent_validation = df_validation['intent_label'].map(intent_map).values\n",
    "intent_test = df_test['intent_label'].map(intent_map).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108310272 (413.17 MB)\n",
      "Trainable params: 108310272 (413.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
    "base_bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'encoder' (type TFBertEncoder).\n\nThe truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n\nCall arguments received by layer 'encoder' (type TFBertEncoder):\n  • hidden_states=tf.Tensor(shape=(700, 45, 768), dtype=float32)\n  • attention_mask=tf.Tensor(shape=(700, 1, 1, 45), dtype=float32)\n  • head_mask=['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None']\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None']\n  • use_cache=False\n  • output_attentions=tf.Tensor(shape=(700, 45), dtype=int32)\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\slot_filling_github_example.ipynb Celda 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling_github_example.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m outputs \u001b[39m=\u001b[39m base_bert_model(encoded_validation)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling_github_example.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mShape of the first output of the BERT model: \u001b[39m\u001b[39m{\u001b[39;00moutputs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling_github_example.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mShape of the second output of the BERT model: \u001b[39m\u001b[39m{\u001b[39;00moutputs[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:426\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    423\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\n\u001b[0;32m    425\u001b[0m unpacked_inputs \u001b[39m=\u001b[39m input_processing(func, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m--> 426\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49munpacked_inputs)\n",
      "File \u001b[1;32mc:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:1088\u001b[0m, in \u001b[0;36mTFBertModel.call\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[39m@unpack_inputs\u001b[39m\n\u001b[0;32m   1045\u001b[0m \u001b[39m@add_start_docstrings_to_model_forward\u001b[39m(BERT_INPUTS_DOCSTRING\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39mbatch_size, sequence_length\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m   1046\u001b[0m \u001b[39m@add_code_sample_docstrings\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     training: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1067\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[TFBaseModelOutputWithPoolingAndCrossAttentions, Tuple[tf\u001b[39m.\u001b[39mTensor]]:\n\u001b[0;32m   1068\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m \u001b[39m    encoder_hidden_states  (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m \u001b[39m        Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1086\u001b[0m \u001b[39m        `past_key_values`). Set to `False` during training, `True` during generation\u001b[39;00m\n\u001b[0;32m   1087\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[0;32m   1089\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m   1090\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1091\u001b[0m         token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1092\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1093\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1094\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1095\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1096\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m   1097\u001b[0m         past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1098\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1099\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1100\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1101\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1102\u001b[0m         training\u001b[39m=\u001b[39;49mtraining,\n\u001b[0;32m   1103\u001b[0m     )\n\u001b[0;32m   1104\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:426\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    423\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\n\u001b[0;32m    425\u001b[0m unpacked_inputs \u001b[39m=\u001b[39m input_processing(func, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m--> 426\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49munpacked_inputs)\n",
      "File \u001b[1;32mc:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:862\u001b[0m, in \u001b[0;36mTFBertMainLayer.call\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    860\u001b[0m     head_mask \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers\n\u001b[1;32m--> 862\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m    863\u001b[0m     hidden_states\u001b[39m=\u001b[39;49membedding_output,\n\u001b[0;32m    864\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m    865\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    866\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    867\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m    868\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m    869\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    870\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    871\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    872\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    873\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[0;32m    874\u001b[0m )\n\u001b[0;32m    876\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    877\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(hidden_states\u001b[39m=\u001b[39msequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:544\u001b[0m, in \u001b[0;36mTFBertEncoder.call\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\n\u001b[0;32m    530\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    531\u001b[0m     hidden_states: tf\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m     training: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    542\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[TFBaseModelOutputWithPastAndCrossAttentions, Tuple[tf\u001b[39m.\u001b[39mTensor]]:\n\u001b[0;32m    543\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m () \u001b[39mif\u001b[39;00m output_hidden_states \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m     all_attentions \u001b[39m=\u001b[39m () \u001b[39mif\u001b[39;00m output_attentions \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    545\u001b[0m     all_cross_attentions \u001b[39m=\u001b[39m () \u001b[39mif\u001b[39;00m output_attentions \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39madd_cross_attention \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    547\u001b[0m     next_decoder_cache \u001b[39m=\u001b[39m () \u001b[39mif\u001b[39;00m use_cache \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer 'encoder' (type TFBertEncoder).\n\nThe truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n\nCall arguments received by layer 'encoder' (type TFBertEncoder):\n  • hidden_states=tf.Tensor(shape=(700, 45, 768), dtype=float32)\n  • attention_mask=tf.Tensor(shape=(700, 1, 1, 45), dtype=float32)\n  • head_mask=['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None']\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None']\n  • use_cache=False\n  • output_attentions=tf.Tensor(shape=(700, 45), dtype=int32)\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False"
     ]
    }
   ],
   "source": [
    "outputs = base_bert_model(encoded_validation)\n",
    "print(f'Shape of the first output of the BERT model: {outputs[0].shape}.')\n",
    "print(f'Shape of the second output of the BERT model: {outputs[1].shape}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
