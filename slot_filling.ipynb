{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (2.14.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from datasets) (1.26.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from datasets) (14.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from aiohttp->datasets) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"multi_woz_v22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: 'dataset.hf\\dataset_dict.json'. Expected to load a `DatasetDict` object, but provided path is not a `DatasetDict`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\slot_filling.ipynb Celda 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m DatasetDict\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dataset \u001b[39m=\u001b[39m DatasetDict\u001b[39m.\u001b[39;49mload_from_disk(\u001b[39m\"\u001b[39;49m\u001b[39mdataset.hf\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\datasets\\dataset_dict.py:1357\u001b[0m, in \u001b[0;36mDatasetDict.load_from_disk\u001b[1;34m(dataset_dict_path, fs, keep_in_memory, storage_options)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[39mif\u001b[39;00m fs\u001b[39m.\u001b[39misfile(dataset_info_path) \u001b[39mand\u001b[39;00m fs\u001b[39m.\u001b[39misfile(dataset_state_json_path):\n\u001b[0;32m   1354\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1355\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo such file: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdataset_dict_json_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Expected to load a `DatasetDict` object, but got a `Dataset`. Please use either `datasets.load_from_disk` or `Dataset.load_from_disk` instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1356\u001b[0m         )\n\u001b[1;32m-> 1357\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1358\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo such file: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdataset_dict_json_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Expected to load a `DatasetDict` object, but provided path is not a `DatasetDict`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1359\u001b[0m     )\n\u001b[0;32m   1361\u001b[0m \u001b[39mwith\u001b[39;00m fs\u001b[39m.\u001b[39mopen(dataset_dict_json_path, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m   1362\u001b[0m     splits \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)[\u001b[39m\"\u001b[39m\u001b[39msplits\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'dataset.hf\\dataset_dict.json'. Expected to load a `DatasetDict` object, but provided path is not a `DatasetDict`."
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "dataset = DatasetDict.load_from_disk(\"dataset.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=[]\n",
    "train_data = dataset['train']\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    data.append(train_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "train_data = dataset['train']\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "  data.append(train_data[i])\n",
    "\n",
    "sentences = []\n",
    "slot_labels = []\n",
    "intent=[]\n",
    "\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data[i]['turns']['speaker'])):\n",
    "\n",
    "        turn = data[i]['turns']['speaker'][j]\n",
    "\n",
    "        if int(turn) == 0 and data[i]['turns']['frames'][j]['state'] != []:\n",
    "            slots_values_list = data[i]['turns']['frames'][j]['state'][0]['slots_values']['slots_values_list']\n",
    "            slots_values_names = data[i]['turns']['frames'][j]['state'][0]['slots_values']['slots_values_name']\n",
    "            intent.append(data[i]['turns']['frames'][j]['state'][0]['active_intent'])\n",
    "            sentences.append(data[i]['turns']['utterance'][j])\n",
    "            words = data[i]['turns']['utterance'][j].split()\n",
    "            words = [word.rstrip('.') for word in words]\n",
    "\n",
    "\n",
    "            label = []\n",
    "            word_count = {}\n",
    "\n",
    "            for word in words:\n",
    "                found = False\n",
    "                if word not in word_count:\n",
    "                    word_count[word] = 1\n",
    "                else:\n",
    "                    word_count[word] += 1\n",
    "\n",
    "                for idx, slot_values in enumerate(slots_values_list):\n",
    "                    if word in slot_values:\n",
    "                        if word_count[word] > 1 and (idx + word_count[word] - 1) < len(slots_values_names):\n",
    "                            label.append(slots_values_names[idx + word_count[word] - 1])\n",
    "                        else:\n",
    "                            label.append(slots_values_names[idx])\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    label.append(0)\n",
    "            converted_list = ['O' if item == 0 else str(item) for item in label]\n",
    "            result = ' '.join(converted_list)\n",
    "            slot_labels.append(converted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          intent_label                                              words  \\\n",
      "0      find_restaurant              I would like an expensive restaurant.   \n",
      "1      book_restaurant         For 7 people at 11:15 on Saturday, please.   \n",
      "2      book_restaurant  Caffe Uno will be fine. Yes, I'll need to rese...   \n",
      "3            find_taxi  Great I also need to get a taxi that can get m...   \n",
      "4      book_restaurant  Can I have a reference number for the restaurant?   \n",
      "...                ...                                                ...   \n",
      "38311  find_restaurant                            Is there anything else?   \n",
      "38312  find_restaurant                        what is there phone number?   \n",
      "38313  find_restaurant  Hello, I am looking for a cheap restaurant tha...   \n",
      "38314  find_restaurant                    Yes, how about portuguese food?   \n",
      "38315  find_restaurant                                 It doesn't matter.   \n",
      "\n",
      "                                             words_label  length  \n",
      "0                 [O, O, O, O, restaurant-pricerange, O]      37  \n",
      "1      [O, restaurant-bookpeople, O, O, restaurant-bo...      42  \n",
      "2      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...     104  \n",
      "3      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...      74  \n",
      "4                            [O, O, O, O, O, O, O, O, O]      49  \n",
      "...                                                  ...     ...  \n",
      "38311                                       [O, O, O, O]      23  \n",
      "38312                                    [O, O, O, O, O]      27  \n",
      "38313  [O, O, O, O, O, O, restaurant-pricerange, O, O...      67  \n",
      "38314                      [O, O, O, restaurant-food, O]      31  \n",
      "38315                                          [O, O, O]      18  \n",
      "\n",
      "[38316 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "lens=[]\n",
    "for i in range(len(sentences)):\n",
    "  lens.append(len(sentences[i]))\n",
    "\n",
    "df_validation = pd.DataFrame({'intent_label': intent[0:4789],'words': sentences[0:4789], 'words_label': slot_labels[0:4789], 'length': lens[0:4789]})\n",
    "df_test = pd.DataFrame({'intent_label': intent[4790:9579],'words': sentences[4790:9579], 'words_label': slot_labels[4790:9579], 'length': lens[4790:9579]})\n",
    "df_train = pd.DataFrame({'intent_label': intent[9580:47896],'words': sentences[9580:47896], 'words_label': slot_labels[9580:47896], 'length': lens[9580:47896]})\n",
    "print(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intent_label\n",
       "find_restaurant    7704\n",
       "find_hotel         7413\n",
       "find_train         6654\n",
       "find_attraction    5344\n",
       "book_restaurant    3229\n",
       "book_hotel         3020\n",
       "find_taxi          2392\n",
       "book_train         1676\n",
       "find_hospital       504\n",
       "find_police         376\n",
       "find_bus              4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of lines by intent label\n",
    "df_train.intent_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from matplotlib) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from matplotlib) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'length'}>]], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "# Histogram of sentence lengths\n",
    "df_train.hist('length', bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent classification (sentence level)¶\n",
    "Let's ignore the slot filling task for now and let's try to build a sentence level classifier by fine-tuning a pre-trained Transformer-based model using the huggingface/transformers package that provides both Tensorflow/Keras and Pytorch APIs.\n",
    "\n",
    "**The BERT tokenizer**\n",
    "First let's load a pre-trained tokenizer and test it on a test sentence from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (4.35.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "model_name = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would like an expensive restaurant.\n"
     ]
    }
   ],
   "source": [
    "first_sentence = df_train.iloc[0]['words']\n",
    "print(first_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'would', 'like', 'an', 'expensive', 'restaurant', '.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(first_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 146, 1156, 1176, 1126, 5865, 4382, 119, 102]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode sentence to id\n",
    "tokenizer.encode(first_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] I would like an expensive restaurant. [SEP]'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the inverse operation\n",
    "tokenizer.decode(tokenizer.encode(first_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks:\n",
    "\n",
    "* The first token [CLS] is used by the pre-training task for sequence classification.\n",
    "* The last token [SEP] is a separator for the pre-training task that classifies if a pair of sentences are consecutive in a corpus or not (next sentence prediction).\n",
    "* Here, we want to use BERT to compute a representation of a single voice command at a time.\n",
    "* We could reuse the representation of the [CLS] token for sequence classification.\n",
    "* Alternatively, we can pool the representations of all the tokens of the voice command (e.g. global average) and use that as the input of the final sequence classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_sequence_lengths = [len(tokenizer.encode(text))\n",
    "                          for text in df_train['words']]\n",
    "plt.hist(train_sequence_lengths, bins=30)\n",
    "plt.title(f'Max sequence length: {max(train_sequence_lengths)}')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform transfer learning, we will need to work with padded sequences. So, they all have the same sizes. The above histograms, shows that after tokenization,  $50$  tokens are enough to represent all the voice commands in the training set.\n",
    "\n",
    "The mapping can be introspected in the tokenizer.vocab attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 28996 words.\n"
     ]
    }
   ],
   "source": [
    "print(f'Vocabulary size: {tokenizer.vocab_size} words.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ä', 250),\n",
       " ('å', 251),\n",
       " ('æ', 252),\n",
       " ('ç', 253),\n",
       " ('è', 254),\n",
       " ('é', 255),\n",
       " ('ê', 256),\n",
       " ('ë', 257),\n",
       " ('ì', 258),\n",
       " ('í', 259)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the items in BERT\n",
    "bert_vocab_items = list(tokenizer.vocab.items())\n",
    "# Print some examples of items\n",
    "bert_vocab_items[250:260]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the dataset with the tokenizer\n",
    "Let's now encode the full train/validation and test sets with our tokenizer to get a padded integer numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dataset(tokenizer, text_sequences, max_length):\n",
    "    token_ids = np.zeros(shape=(len(text_sequences), max_length),\n",
    "                         dtype=np.int32)\n",
    "    for i, text_sequence in enumerate(text_sequences):\n",
    "        encoded = tokenizer.encode(text_sequence)\n",
    "        token_ids[i, 0:len(encoded)] = encoded\n",
    "    attention_masks = (token_ids != 0).astype(np.int32)\n",
    "\n",
    "    return {'input_ids': token_ids, 'attention_masks': attention_masks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "encoded_train = encode_dataset(tokenizer, df_train['words'], 90)\n",
    "encoded_validation = encode_dataset(tokenizer, df_validation['words'], 90)\n",
    "encoded_test = encode_dataset(tokenizer, df_test['words'], 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the sequence classification targets\n",
    "To do so, we build a simple mapping from the auxiliary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book_hotel': 0,\n",
       " 'find_restaurant': 1,\n",
       " 'find_bus': 2,\n",
       " 'book_restaurant': 3,\n",
       " 'find_hospital': 4,\n",
       " 'find_taxi': 5,\n",
       " 'find_police': 6,\n",
       " 'book_train': 7,\n",
       " 'find_attraction': 8,\n",
       " 'find_train': 9,\n",
       " 'find_hotel': 10}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_names = set(intent)\n",
    "intent_map = dict((label, idx) for idx, label in enumerate(intent_names))\n",
    "intent_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_train = df_train['intent_label'].map(intent_map).values\n",
    "intent_validation = df_validation['intent_label'].map(intent_map).values\n",
    "intent_test = df_test['intent_label'].map(intent_map).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and feeding a pretrained BERT model\n",
    "Let's load a pretrained BERT model using the huggingface transformers package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: TensorFlow in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (2.14.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from TensorFlow) (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (1.26.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (4.25.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (1.59.2)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->TensorFlow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->TensorFlow) (0.41.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->TensorFlow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->TensorFlow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->TensorFlow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->TensorFlow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->TensorFlow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->TensorFlow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->TensorFlow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->TensorFlow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->TensorFlow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->TensorFlow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->TensorFlow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->TensorFlow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->TensorFlow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->TensorFlow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->TensorFlow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->TensorFlow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->TensorFlow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Downloading model.safetensors: 100%|██████████| 436M/436M [00:16<00:00, 25.7MB/s] \n",
      "c:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\neusv\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108310272 (413.17 MB)\n",
      "Trainable params: 108310272 (413.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "!pip install TensorFlow\n",
    "import transformers\n",
    "\n",
    "base_bert_model = TFBertModel.from_pretrained(model_name)\n",
    "base_bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = base_bert_model(encoded_validation)\n",
    "print(f'Shape of the first output of the BERT model: {outputs[0].shape}.')\n",
    "print(f'Shape of the second output of the BERT model: {outputs[1].shape}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define IntentClassification model\n",
    "class IntentClassificationModel(tf.keras.Model):\n",
    "    def __init__(self, intent_num_labels=None,\n",
    "                 model_name='bert-base-cased',\n",
    "                 dropout_prob=0.1):\n",
    "        super().__init__(name='joint_intent_slot')\n",
    "        # Let's preload the pretrained model BERT in the constructor\n",
    "        # of our classifier model.\n",
    "        self.bert = TFBertModel.from_pretrained(model_name)\n",
    "        self.dropout = Dropout(dropout_prob)\n",
    "\n",
    "        # Define a (Dense) classification layer to compute for each\n",
    "        # sequence in a batch of samples. The number of output classes\n",
    "        # is given by the intent_num_labels parameter.\n",
    "        # Use the default linear activation (no softmax) to compute\n",
    "        # logits. The softmax normalization will be computed in the\n",
    "        # loss function instead of the model itself.\n",
    "        self.intent_classifier = Dense(intent_num_labels)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        # Use the pretrained model to extract features from our\n",
    "        # encoded inputs.\n",
    "        sequence_output, pooled_output = self.bert(inputs, **kwargs)\n",
    "\n",
    "        # The second output of the main BERT layer has shape:\n",
    "        # (batch_size, output_dim) and gives a \"pooled\" representation\n",
    "        # for the full sequence from the hidden state that corresponds\n",
    "        # to the \"[CLS]\" token.\n",
    "        pooled_output = self.dropout(pooled_output, training=kwargs.get('training', False))\n",
    "\n",
    "        # Use the classifier layer to compute the logits from the\n",
    "        # pooled features.\n",
    "        intent_logits = self.intent_classifier(pooled_output)\n",
    "        return intent_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "intent_model = IntentClassificationModel(intent_num_labels=len(intent_map))\n",
    "\n",
    "intent_model.compile(optimizer=Adam(learning_rate=3e-5, epsilon=1e-08),\n",
    "                     loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                     metrics=[SparseCategoricalAccuracy('accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\neusv\\AppData\\Local\\Temp\\__autograph_generated_filea3znfh4h.py\", line 10, in tf__call\n        sequence_output, pooled_output = ag__.converted_call(ag__.ld(self).bert, (ag__.ld(inputs),), dict(**ag__.ld(kwargs)), fscope)\n    File \"C:\\Users\\neusv\\AppData\\Local\\Temp\\__autograph_generated_filer7l1kwla.py\", line 40, in tf__run_call_with_unpacked_inputs\n        raise\n\n    TypeError: Exception encountered when calling layer 'joint_intent_slot' (type IntentClassificationModel).\n    \n    in user code:\n    \n        File \"C:\\Users\\neusv\\AppData\\Local\\Temp\\ipykernel_60960\\298034465.py\", line 29, in call  *\n            sequence_output, pooled_output = self.bert(inputs, **kwargs)\n        File \"c:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\neusv\\AppData\\Local\\Temp\\__autograph_generated_filer7l1kwla.py\", line 40, in tf__run_call_with_unpacked_inputs\n            raise\n    \n        TypeError: Exception encountered when calling layer 'tf_bert_model_1' (type TFBertModel).\n        \n        in user code:\n        \n            File \"c:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1061, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n        \n            TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__call() got an unexpected keyword argument 'attention_masks'\n        \n        \n        Call arguments received by layer 'tf_bert_model_1' (type TFBertModel):\n          • input_ids={'input_ids': 'tf.Tensor(shape=(None, 90), dtype=int32)', 'attention_masks': 'tf.Tensor(shape=(None, 90), dtype=int32)'}\n          • attention_mask=None\n          • token_type_ids=None\n          • position_ids=None\n          • head_mask=None\n          • inputs_embeds=None\n          • encoder_hidden_states=None\n          • encoder_attention_mask=None\n          • past_key_values=None\n          • use_cache=None\n          • output_attentions=None\n          • output_hidden_states=None\n          • return_dict=None\n          • training=True\n    \n    \n    Call arguments received by layer 'joint_intent_slot' (type IntentClassificationModel):\n      • inputs={'input_ids': 'tf.Tensor(shape=(None, 90), dtype=int32)', 'attention_masks': 'tf.Tensor(shape=(None, 90), dtype=int32)'}\n      • kwargs={'training': 'True'}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\slot_filling.ipynb Celda 26\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#Probably we need to add ['inputs_id'] to the data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m history \u001b[39m=\u001b[39m intent_model\u001b[39m.\u001b[39;49mfit(encoded_train, intent_train,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                            epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                            validation_data\u001b[39m=\u001b[39;49m(encoded_validation, intent_validation))\n",
      "File \u001b[1;32mc:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileobvwwu1u.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filea3znfh4h.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m sequence_output, pooled_output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mbert, (ag__\u001b[39m.\u001b[39;49mld(inputs),), \u001b[39mdict\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(kwargs)), fscope)\n\u001b[0;32m     11\u001b[0m pooled_output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mdropout, (ag__\u001b[39m.\u001b[39mld(pooled_output),), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(kwargs)\u001b[39m.\u001b[39mget, (\u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m), \u001b[39mNone\u001b[39;00m, fscope)), fscope)\n\u001b[0;32m     12\u001b[0m intent_logits \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mintent_classifier, (ag__\u001b[39m.\u001b[39mld(pooled_output),), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filer7l1kwla.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(func), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m),), \u001b[39mdict\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mag__\u001b[39m.\u001b[39mld(unpacked_inputs)), fscope)\n\u001b[0;32m     38\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"c:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\neusv\\AppData\\Local\\Temp\\__autograph_generated_filea3znfh4h.py\", line 10, in tf__call\n        sequence_output, pooled_output = ag__.converted_call(ag__.ld(self).bert, (ag__.ld(inputs),), dict(**ag__.ld(kwargs)), fscope)\n    File \"C:\\Users\\neusv\\AppData\\Local\\Temp\\__autograph_generated_filer7l1kwla.py\", line 40, in tf__run_call_with_unpacked_inputs\n        raise\n\n    TypeError: Exception encountered when calling layer 'joint_intent_slot' (type IntentClassificationModel).\n    \n    in user code:\n    \n        File \"C:\\Users\\neusv\\AppData\\Local\\Temp\\ipykernel_60960\\298034465.py\", line 29, in call  *\n            sequence_output, pooled_output = self.bert(inputs, **kwargs)\n        File \"c:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\neusv\\AppData\\Local\\Temp\\__autograph_generated_filer7l1kwla.py\", line 40, in tf__run_call_with_unpacked_inputs\n            raise\n    \n        TypeError: Exception encountered when calling layer 'tf_bert_model_1' (type TFBertModel).\n        \n        in user code:\n        \n            File \"c:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1061, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n        \n            TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__call() got an unexpected keyword argument 'attention_masks'\n        \n        \n        Call arguments received by layer 'tf_bert_model_1' (type TFBertModel):\n          • input_ids={'input_ids': 'tf.Tensor(shape=(None, 90), dtype=int32)', 'attention_masks': 'tf.Tensor(shape=(None, 90), dtype=int32)'}\n          • attention_mask=None\n          • token_type_ids=None\n          • position_ids=None\n          • head_mask=None\n          • inputs_embeds=None\n          • encoder_hidden_states=None\n          • encoder_attention_mask=None\n          • past_key_values=None\n          • use_cache=None\n          • output_attentions=None\n          • output_hidden_states=None\n          • return_dict=None\n          • training=True\n    \n    \n    Call arguments received by layer 'joint_intent_slot' (type IntentClassificationModel):\n      • inputs={'input_ids': 'tf.Tensor(shape=(None, 90), dtype=int32)', 'attention_masks': 'tf.Tensor(shape=(None, 90), dtype=int32)'}\n      • kwargs={'training': 'True'}\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "#Probably we need to add ['inputs_id'] to the data\n",
    "history = intent_model.fit(encoded_train, intent_train,\n",
    "                           epochs=2, batch_size=32,\n",
    "                           validation_data=(encoded_validation, intent_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text, tokenizerzer, model, intent_names):\n",
    "    inputs = tf.constant(tokenizer.encode(text))[None, :] # Batch size = 1\n",
    "    class_id = model(inputs).numpy().argmax(axis=1)[0]\n",
    "    return intent_names[class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'joint_intent_slot' (type IntentClassificationModel).\n\nInput 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=0. Full shape received: ()\n\nCall arguments received by layer 'joint_intent_slot' (type IntentClassificationModel):\n  • inputs=tf.Tensor(shape=(1, 9), dtype=int32)\n  • kwargs={'training': 'None'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\slot_filling.ipynb Celda 28\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Example of classification\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m classify(\u001b[39m'\u001b[39;49m\u001b[39mWill it snow tomorrow in Paris?\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m          tokenizer, intent_model, intent_names)\n",
      "\u001b[1;32mc:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\slot_filling.ipynb Celda 28\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclassify\u001b[39m(text, tokenizerzer, model, intent_names):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     inputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(tokenizer\u001b[39m.\u001b[39mencode(text))[\u001b[39mNone\u001b[39;00m, :] \u001b[39m# Batch size = 1\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     class_id \u001b[39m=\u001b[39m model(inputs)\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m intent_names[class_id]\n",
      "File \u001b[1;32mc:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;32mc:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\slot_filling.ipynb Celda 28\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X36sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output, training\u001b[39m=\u001b[39mkwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X36sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Use the classifier layer to compute the logits from the\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X36sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# pooled features.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X36sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m intent_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintent_classifier(pooled_output)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X36sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mreturn\u001b[39;00m intent_logits\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer 'joint_intent_slot' (type IntentClassificationModel).\n\nInput 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=0. Full shape received: ()\n\nCall arguments received by layer 'joint_intent_slot' (type IntentClassificationModel):\n  • inputs=tf.Tensor(shape=(1, 9), dtype=int32)\n  • kwargs={'training': 'None'}"
     ]
    }
   ],
   "source": [
    "# Example of classification\n",
    "classify('Can I book a table for 2?',\n",
    "         tokenizer, intent_model, intent_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pathlib in c:\\users\\neusv\\onedrive\\documentos\\emai upf\\natural lenguage interaction\\project chatbot\\nlp-chat-bot-project\\env\\lib\\site-packages (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pathlib\n",
    "from pathlib import Path\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from urllib.request import urlretrieve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O', 'O', 'restaurant-pricerange', 'O']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['words_label'][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join intent classification and slot filling\n",
    "Let's now refine our natural language understanding system by trying to retrieve the important structured elements of each voice command. To do so, we will perform word level (or token level) classification of the BIO labels. Since we have word level tags but BERT uses a wordpiece tokenizer, we need to align the BIO labels with the BERT tokens. Let's load the list of possible word token labels and augment it with an additional padding label to be able to ignore special tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'restaurant-pricerange': 0,\n",
       " 'restaurant-bookpeople': 1,\n",
       " 'restaurant-booktime': 2,\n",
       " 'taxi-arriveby': 3,\n",
       " 'train-day': 4,\n",
       " 'train-arriveby': 5,\n",
       " 'restaurant-food': 6,\n",
       " 'train-destination': 7,\n",
       " 'train-bookpeople': 8,\n",
       " 'taxi-destination': 9,\n",
       " 'hotel-pricerange': 10,\n",
       " 'hotel-area': 11,\n",
       " 'restaurant-area': 12,\n",
       " 'attraction-type': 13,\n",
       " 'restaurant-bookday': 14,\n",
       " 'hotel-type': 15,\n",
       " 'hotel-stars': 16,\n",
       " 'attraction-area': 17,\n",
       " 'taxi-leaveat': 18,\n",
       " 'hotel-bookpeople': 19,\n",
       " 'hotel-bookstay': 20,\n",
       " 'hotel-bookday': 21,\n",
       " 'train-departure': 22,\n",
       " 'train-leaveat': 23,\n",
       " 'restaurant-name': 24,\n",
       " 'hotel-name': 25,\n",
       " 'hospital-department': 26,\n",
       " 'taxi-departure': 27,\n",
       " 'hotel-internet': 28,\n",
       " 'hotel-parking': 29,\n",
       " 'attraction-name': 30,\n",
       " 'bus-destination': 31}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data\n",
    "slot_names = []\n",
    "\n",
    "for i in range(len(df_train)):\n",
    "    for j in range(len(df_train['words_label'][i])):\n",
    "        item = df_train['words_label'][i][j]\n",
    "        if  item != 'O' and item not in slot_names:\n",
    "            slot_names.append(item)\n",
    "\n",
    "slot_map = dict({slot: index for index, slot in enumerate(slot_names)})\n",
    "slot_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_token_labels(text_sequences, slot_names, tokenizer, slot_map, max_length):\n",
    "    encoded = np.zeros(shape=(len(text_sequences), max_length), dtype=np.int32)\n",
    "    for i, (text_sequence, word_labels) in enumerate(\n",
    "            zip(text_sequences, slot_names)):\n",
    "        encoded_labels = []\n",
    "        for word, word_label in zip(text_sequence.split(), word_labels.split()):\n",
    "            tokens = tokenizer.tokenize(word)\n",
    "            encoded_labels.append(slot_map[word_label])\n",
    "            expand_label = word_label.replace(\"B-\", \"I-\")\n",
    "            if not expand_label in slot_map:\n",
    "                expand_label = word_label\n",
    "            encoded_labels.extend([slot_map[expand_label]] * (len(tokens) - 1))\n",
    "        encoded[i, 1:len(encoded_labels) + 1] = encoded_labels\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\slot_filling.ipynb Celda 33\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m slot_train \u001b[39m=\u001b[39m encode_token_labels(df_train[\u001b[39m'\u001b[39;49m\u001b[39mwords\u001b[39;49m\u001b[39m'\u001b[39;49m], df_train[\u001b[39m'\u001b[39;49m\u001b[39mwords_label\u001b[39;49m\u001b[39m'\u001b[39;49m], tokenizer, slot_map, \u001b[39m45\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m slot_validation \u001b[39m=\u001b[39m encode_token_labels(df_validation[\u001b[39m'\u001b[39m\u001b[39mwords\u001b[39m\u001b[39m'\u001b[39m], df_validation[\u001b[39m'\u001b[39m\u001b[39mwords_label\u001b[39m\u001b[39m'\u001b[39m], tokenizer, slot_map, \u001b[39m45\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m slot_test \u001b[39m=\u001b[39m encode_token_labels(df_test[\u001b[39m'\u001b[39m\u001b[39mwords\u001b[39m\u001b[39m'\u001b[39m], df_test[\u001b[39m'\u001b[39m\u001b[39mwords_label\u001b[39m\u001b[39m'\u001b[39m], tokenizer, slot_map, \u001b[39m45\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\slot_filling.ipynb Celda 33\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (text_sequence, word_labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X44sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39mzip\u001b[39m(text_sequences, slot_names)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     encoded_labels \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X44sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m word, word_label \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(text_sequence\u001b[39m.\u001b[39msplit(), word_labels\u001b[39m.\u001b[39;49msplit()):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         tokens \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mtokenize(word)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         encoded_labels\u001b[39m.\u001b[39mappend(slot_map[word_label])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "slot_train = encode_token_labels(df_train['words'], df_train['words_label'], tokenizer, slot_map, 45)\n",
    "slot_validation = encode_token_labels(df_validation['words'], df_validation['words_label'], tokenizer, slot_map, 45)\n",
    "slot_test = encode_token_labels(df_test['words'], df_test['words_label'], tokenizer, slot_map, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'slot_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\neusv\\OneDrive\\Documentos\\EMAI UPF\\NATURAL LENGUAGE INTERACTION\\Project ChatBot\\NLP-Chat-Bot-project\\slot_filling.ipynb Celda 34\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/neusv/OneDrive/Documentos/EMAI%20UPF/NATURAL%20LENGUAGE%20INTERACTION/Project%20ChatBot/NLP-Chat-Bot-project/slot_filling.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m slot_train\n",
      "\u001b[1;31mNameError\u001b[0m: name 'slot_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Define JointIntentAndSlotFilling model\n",
    "class JointIntentAndSlotFillingModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, intent_num_labels=None, slot_num_labels=None,\n",
    "                 model_name=\"bert-base-cased\", dropout_prob=0.1):\n",
    "        super().__init__(name=\"joint_intent_slot\")\n",
    "        self.bert = TFBertModel.from_pretrained(model_name)\n",
    "        self.dropout = Dropout(dropout_prob)\n",
    "        self.intent_classifier = Dense(intent_num_labels,\n",
    "                                       name=\"intent_classifier\")\n",
    "        self.slot_classifier = Dense(slot_num_labels,\n",
    "                                     name=\"slot_classifier\")\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        sequence_output, pooled_output = self.bert(inputs, **kwargs)\n",
    "\n",
    "        # The first output of the main BERT layer has shape:\n",
    "        # (batch_size, max_length, output_dim)\n",
    "        sequence_output = self.dropout(sequence_output,\n",
    "                                       training=kwargs.get(\"training\", False))\n",
    "        slot_logits = self.slot_classifier(sequence_output)\n",
    "\n",
    "        # The second output of the main BERT layer has shape:\n",
    "        # (batch_size, output_dim)\n",
    "        # and gives a \"pooled\" representation for the full sequence from the\n",
    "        # hidden state that corresponds to the \"[CLS]\" token.\n",
    "        pooled_output = self.dropout(pooled_output,\n",
    "                                     training=kwargs.get(\"training\", False))\n",
    "        intent_logits = self.intent_classifier(pooled_output)\n",
    "\n",
    "        return slot_logits, intent_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_model = JointIntentAndSlotFillingModel(\n",
    "    intent_num_labels=len(intent_map), slot_num_labels=len(slot_map))\n",
    "\n",
    "# Define one classification loss for each output:\n",
    "opt = Adam(learning_rate=3e-5, epsilon=1e-08)\n",
    "losses = [SparseCategoricalCrossentropy(from_logits=True),\n",
    "          SparseCategoricalCrossentropy(from_logits=True)]\n",
    "metrics = [SparseCategoricalAccuracy('accuracy')]\n",
    "joint_model.compile(optimizer=opt, loss=losses, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = joint_model.fit(\n",
    "    encoded_train, (slot_train, intent_train),\n",
    "    validation_data=(encoded_validation, (slot_validation, intent_validation)),\n",
    "    epochs=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(text, tokenizer, model, intent_names, slot_names):\n",
    "    inputs = tf.constant(tokenizer.encode(text))[None, :]  # batch_size = 1\n",
    "    outputs = model(inputs)\n",
    "    slot_logits, intent_logits = outputs\n",
    "    slot_ids = slot_logits.numpy().argmax(axis=-1)[0, 1:-1]\n",
    "    intent_id = intent_logits.numpy().argmax(axis=-1)[0]\n",
    "    print(\"## Intent:\", intent_names[intent_id])\n",
    "    print(\"## Slots:\")\n",
    "    for token, slot_id in zip(tokenizer.tokenize(text), slot_ids):\n",
    "        print(f\"{token:>10} : {slot_names[slot_id]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXAMPLE OF PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions('Will it snow tomorrow in Paris?',\n",
    "                 tokenizer, joint_model, intent_names, slot_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding predictions into structured knowledge\n",
    "For completeness, here a minimal functional to naively decode the predicted BIO slot ids and convert it into a structured representation for the detected slots as a Python dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(text, tokenizer, intent_names, slot_names,\n",
    "                       intent_id, slot_ids):\n",
    "    info = {\"intent\": intent_names[intent_id]}\n",
    "    collected_slots = {}\n",
    "    active_slot_words = []\n",
    "    active_slot_name = None\n",
    "    for word in text.split():\n",
    "        tokens = tokenizer.tokenize(word)\n",
    "        current_word_slot_ids = slot_ids[:len(tokens)]\n",
    "        slot_ids = slot_ids[len(tokens):]\n",
    "        current_word_slot_name = slot_names[current_word_slot_ids[0]]\n",
    "        if current_word_slot_name == \"O\":\n",
    "            if active_slot_name:\n",
    "                collected_slots[active_slot_name] = \" \".join(active_slot_words)\n",
    "                active_slot_words = []\n",
    "                active_slot_name = None\n",
    "        else:\n",
    "            # Naive BIO: handling: treat B- and I- the same...\n",
    "            new_slot_name = current_word_slot_name[2:]\n",
    "            if active_slot_name is None:\n",
    "                active_slot_words.append(word)\n",
    "                active_slot_name = new_slot_name\n",
    "            elif new_slot_name == active_slot_name:\n",
    "                active_slot_words.append(word)\n",
    "            else:\n",
    "                collected_slots[active_slot_name] = \" \".join(active_slot_words)\n",
    "                active_slot_words = [word]\n",
    "                active_slot_name = new_slot_name\n",
    "    if active_slot_name:\n",
    "        collected_slots[active_slot_name] = \" \".join(active_slot_words)\n",
    "    info[\"slots\"] = collected_slots\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlu(text, tokenizer, model, intent_names, slot_names):\n",
    "    inputs = tf.constant(tokenizer.encode(text))[None, :]  # batch_size = 1\n",
    "    outputs = model(inputs)\n",
    "    slot_logits, intent_logits = outputs\n",
    "    slot_ids = slot_logits.numpy().argmax(axis=-1)[0, 1:-1]\n",
    "    intent_id = intent_logits.numpy().argmax(axis=-1)[0]\n",
    "\n",
    "    return decode_predictions(text, tokenizer, intent_names, slot_names,\n",
    "                              intent_id, slot_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu('Will it snow tomorrow in Paris?',\n",
    "                 tokenizer, joint_model, intent_names, slot_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu('I would like to listen to Wake me up by Avicii.',\n",
    "    tokenizer, joint_model, intent_names, slot_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
